{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Callable, NamedTuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de tipos\n",
    "FuncionActivacion = Tuple[Callable[[np.ndarray], np.ndarray],\n",
    "    Callable[[np.ndarray], np.ndarray]]\n",
    "Pesos = np.ndarray\n",
    "CapaNeuronal = Tuple[Pesos, np.ndarray, FuncionActivacion]\n",
    "Modelo = NamedTuple('Modelo',\n",
    "    [(\"train\",\n",
    "        Callable[[List[List[int]], List[int], int], List[CapaNeuronal]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de activación y sus derivadas\n",
    "def sigmoide(z: np.ndarray) -> np.ndarray:\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def derivada_sigmoide(z: np.ndarray) -> np.ndarray:\n",
    "    sig = sigmoide(z)\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "def derivada_tanh(z: np.ndarray) -> np.ndarray:\n",
    "    return 1 - np.tanh(z)**2\n",
    "\n",
    "def derivada_relu(z: np.ndarray) -> np.ndarray:\n",
    "    return (z > 0).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_capas_neuronales(neuronas_por_capa: List[int],\n",
    "        funciones_activacion: List[FuncionActivacion]) -> List[CapaNeuronal]:\n",
    "    \"\"\"\n",
    "    Crear una lista de capas neuronales con pesos, sesgos y funciones de\n",
    "    activación.\n",
    "\n",
    "    :param neuronas_por_capa: Lista con el número de neuronas en cada capa.\n",
    "    :param funciones_activacion: Lista con funciones de activación para cada\n",
    "    capa.\n",
    "    :return: Lista de capas neuronales, cada una de las cuales es una tupla con\n",
    "    pesos, sesgos y función de activación.\n",
    "    \"\"\"\n",
    "    capas_neuronales = []\n",
    "    for capa_actual, siguiente_capa, funcion_activacion \\\n",
    "            in zip(neuronas_por_capa[:-1], neuronas_por_capa[1:],\n",
    "                funciones_activacion):\n",
    "        pesos = np,random.randn(siguiente_capa, capa_actual) * \\\n",
    "            np.sqrt(2. / capa_actual) # Método de He\n",
    "        sesgos = np.zeros((siguiente_capa, 1))\n",
    "        capas_neuronales.append((pesos, sesgos, funcion_activacion))\n",
    "    return capas_neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagacion_hacia_adelante(entradas: np.ndarray,\n",
    "        lista_capas_neuronales: List[CapaNeuronal]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Realizar la propagación hacia adelante a través de la red neuronal.\n",
    "\n",
    "    :param entradas: Matriz de entradas donde cada columna es un caso y cada\n",
    "    fila un nodo de la capa actual.\n",
    "    :param lista_capas_neuronales: Lista de capas neuronales.\n",
    "    :return: Lista de valores de activación para cada capa\n",
    "    \"\"\"\n",
    "    valores_activacion_capa = [entradas]\n",
    "    # iteración secuencial\n",
    "    for pesos, sesgos, funcion_activacion in lista_capas_neuronales:\n",
    "        z = np.dot(pesos, valores_activacion_capa[-1]) + sesgos\n",
    "        valor_activacion = funcion_activacion(z)\n",
    "        valores_activacion_capa.append(valor_activacion)\n",
    "    return valores_activacion_capa[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_cuadratico(predicho: np.ndarray, deseado: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcula el error cuadrático entre los valores predichos y los valores\n",
    "    deseados.\n",
    "\n",
    "    :param predicho: Valores predichos por el modelo.\n",
    "    :param deseado: Valores deseados.\n",
    "    :return: Error cuadrático.\n",
    "    \"\"\"\n",
    "    return np.mean((deseado - predicho)**2)\n",
    "\n",
    "def error_cuadratico_derivada(predicho: np.ndarray,\n",
    "        deseado: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calcular la derivada del error cuadrático entre los valores predichos y los\n",
    "    valores deseados.\n",
    "\n",
    "    :param predicho: Valores predichos por el modelo.\n",
    "    :param deseado: Valores deseados.\n",
    "    :return: Derivada del error cuadrático\n",
    "    \"\"\"\n",
    "    return 2 * (deseado - predicho) / predicho.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retropropagacion(entradas: np.ndarray, salidas: np.ndarray,\n",
    "        resultados_capa_z: List[np.ndarray],\n",
    "        lista_capas_neuronales: List[CapaNeuronal]) \\\n",
    "            -> List[Tuple[np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Realizar la retropropagación a través de la red neuronal para calcular los\n",
    "    gradientes.\n",
    "\n",
    "    :param entradas: Entradas de la red neuronal.\n",
    "    :param salidas: Valores deseados de salida.\n",
    "    :param resultados_capa_z: Resultados de la activación para cada capa.\n",
    "    :param lista_capas_neuronales: Lista de capas neuronales.\n",
    "    :return: Lista de gradientes parciales (dZ, dW, db) para cada capa.\n",
    "    \"\"\"\n",
    "\n",
    "    gradientes_parciales = []\n",
    "    \n",
    "    # Última capa\n",
    "    pesos_ultima_capa, _, funciones_activacion_ultima_capa \\\n",
    "        = lista_capas_neuronales[-1]\n",
    "    valor_final = resultados_capa_z[-1]\n",
    "    derivada_costo = error_cuadratico_derivada(valor_final, salidas)\n",
    "    dA = derivada_costo * funciones_activacion_ultima_capa[1](valor_final)\n",
    "    dW = np.dot(dA, resultados_capa_z[-2].T)\n",
    "    db = np.sum(dA, axis=1, keepdims=True)\n",
    "    dZ = np.dot(pesos_ultima_capa.T, dA)\n",
    "\n",
    "    gradientes_parciales.append((dZ, dW, db))\n",
    "\n",
    "    # Retropropagación para las capas anteriores\n",
    "    for i in range(len(lista_capas_neuronales) - 2, -1, -1):\n",
    "        pesos, _, funcion_activacion = lista_capas_neuronales[i]\n",
    "        dZ = np.multiply(np.dot(pesos.T, dZ),\n",
    "            funcion_activacion_capa[1](resultados_capa_z[i]))\n",
    "        dW = np.dot(dZ, resultados_capa_z[i - 1].T)\n",
    "        db = np.sum(dZ, axis=1, keepdims=True)\n",
    "        gradientes_parciales.append((dZ, dW, db))\n",
    "    \n",
    "    # Invertir la lista para que esté en el orden correcto\n",
    "    return gradientes_parciales[::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_parametros(lista_capas_neuronales: List[CapaNeuronal],\n",
    "        gradientes: List[Tuple[np.ndarray, np.ndarray, np.ndarray]],\n",
    "        tasa_aprendizaje: float) -> List[CapaNeuronal]:\n",
    "    \"\"\"\n",
    "    Actualizar los parámetros (pesos y sesgos) de las capas neuronales usando\n",
    "    gradientes y tasa de aprendizaje.\n",
    "\n",
    "    :param gradientes: Lista de gradientes (dZ, dW, db) para cada capa.\n",
    "    :param tasa_aprendizaje: Tasa de aprendizaje para la actualización.\n",
    "    :return: Lista actualizada de capas neuronales.\n",
    "    \"\"\"\n",
    "    nueva_lista_capas_neuronales = []\n",
    "    for (pesos, sesgos, funcion_activacion), (_, dW, db) \\\n",
    "            in zip(lista_capas_neuronales, gradientes):\n",
    "        nuevos_pesos = pesos - tasa_aprendizaje * dW\n",
    "        nuevos_sesgos = sesgos - tasa_aprendizaje * db\n",
    "        nueva_lista_capas_neuronales.append((nuevos_pesos, nuevos_sesgos,\n",
    "            funcion_activacion))\n",
    "    return nueva_lista_capas_neuronales\n",
    "\n",
    "def entrenar(lista_capas_neuronales_inicial: List[CapaNeuronal],\n",
    "        tasa_aprendizaje: float, entradas: List[List[int]], salidas: List[int],\n",
    "        epocas: int = 1000) -> List[CapaNeuronal]:\n",
    "    \"\"\"\n",
    "    Entrenar la red neuronal utilizando el algoritmo de retropropagación.\n",
    "\n",
    "    :param lista_capas_neuronales_inicial: Lista inicial de capas neuronales.\n",
    "    :param tasa_aprendizaje: Tasa de aprendizaje para la actualización de\n",
    "    parámetros.\n",
    "    :param entradas: Datos de entrada para el entrenamiento.\n",
    "    :param salidas: Valores deseados de salida para el entrenamiento.\n",
    "    :param epocas: Número de épocas para entrenar la red.\n",
    "    :return: Lista de capas neuronales entrenadas.\n",
    "    \"\"\"\n",
    "    lista_capas_neuronales = lista_capas_neuronales_inicial\n",
    "    vector_entradas = np.array(entradas).T\n",
    "    vector_salidas = np.array(salidas).T\n",
    "\n",
    "    for epoca in range(1, epocas + 1):\n",
    "        resultados_capas = propagacion_hacia_adelante(vector_entradas,\n",
    "            lista_capas_neuronales)\n",
    "        costo = error_cuadratico(resultados_capas[-1],\n",
    "            vector_salidas) # Error promedio\n",
    "        gradientes = retropropagacion(vector_entradas, vector_salidas,\n",
    "            resultados_capas, lista_capas_neuronales)\n",
    "        lista_capas_neuronales = actualizar_parametros(lista_capas_neuronales,\n",
    "            gradientes, tasa_aprendizaje)\n",
    "\n",
    "        if epoca % 100 == 0:\n",
    "            print(f\"Costo después de la iteración #{epoca}: {costo}\")\n",
    "    \n",
    "    return lista_capas_neuronales\n",
    "\n",
    "def crear_modelo_red_neuronal(neuronas_por_capa: List[int],\n",
    "        funciones_activacion: List[FuncionActivacion],\n",
    "        tasa_aprendizaje: float) -> Modelo:\n",
    "    \"\"\"\n",
    "    Crear un modelo de red neuronal con las características dadas.\n",
    "\n",
    "    :param neuronas_por_capa: Lista con el número de neuronas en cada capa.\n",
    "    :param funciones_activacion: Lista de funciones de activación por cada\n",
    "    capa.\n",
    "    :param tasa_aprendizaje: Tasa de aprendizaje para el entrenamiento.\n",
    "    :return: Modelo de red neuronal.\n",
    "    \"\"\"\n",
    "    lista_capas_neuronales = crear_capas_neuronales(neuronas_por_capa,\n",
    "        funciones_activacion)\n",
    "    print(f\"Modelo inicial aleatorio: {lista_capas_neuronales}\")\n",
    "    return Modelo(partial(entrenar, lista_capas_neuronales, tasa_aprendizaje))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
